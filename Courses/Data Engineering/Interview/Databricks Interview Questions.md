**Basic Concepts & Features**

1.  What is Databricks?
2.  Explain the basic concepts in Databricks.
3.  What are the benefits of using Databricks?
4.  What is Databricks Spark?
5.  What is DBU in Databricks?
6.  What are the core features of Databricks?
7.  What is a Databricks cluster?
8.  What are the different types of clusters in Databricks?
9.  What are the different Databricks runtimes?
10. How do you select a runtime in Databricks?
11. What is caching in Databricks?
12. What are the different types of caching?
13. Should you clean up dataframes that are not in use?
14. What is a Databricks personal access token and how do you create one?
15. What steps should you take to revoke a private access token?
16. What is a Databricks workspace?
17. How does Databricks handle both batch and streaming data?
18. What is Delta Lake?
19. What is MLflow?
20. What is Unity Catalog?
21. How is Azure Databricks different from Databricks?
22. What is the SQL version used in Databricks?
23. Can you use Databricks with Azure Notebooks?
24. What is Databricks Connect?
25. What is the optimized Spark engine in Databricks?

**Data Processing & Transformation**

26. Describe a dataflow map.
27. What are the different applications for Databricks table storage?
28. How do you handle Databricks code while working with Git or TFS in a team?
29. Can you use Spark for streaming data?
30. Do compressed data sources like `.csv.gz` get distributed in Apache Spark?
31. Do you select all columns of a CSV file when using schema with Spark `read`?
32. Is the implementation of PySpark DataFrames entirely unique when compared to that of other Python DataFrames?
33. What is serverless data processing in Databricks?
34. What are the ETL operations done on Databricks?
35. Describe a complex data transformation project you implemented using Databricks.

**Security & Access Control**

36. How do you secure sensitive information in Databricks?
37. What are Secret Scopes in Databricks?
38. What is Role-Based Access Control (RBAC) in Databricks?

**Performance & Optimization**

39. How can you improve the performance of queries in Databricks?
40. How would you handle a scenario where a Spark job in Databricks is failing due to memory issues?
41. How can you optimize Spark jobs in Databricks?
42. What is Photon-Optimized runtime and when to use it?
43. What is GPU-Accelerated Runtime and when to use it?

**Integration & Deployment**

44. What are the stages of a CI/CD pipeline in Databricks?
45. How does Databricks integrate with Azure Data Lake?
46. What are the methods to transfer data from on-premises storage to Microsoft Azure?
47. How can you move information from an on-premises database to Microsoft Azure?
48. What is Kafka and its uses?
49. How does Microsoft Azure handle the redundant storage of data?
50. Does Text Processing support all languages in Databricks? How are multiple languages implicated?



## Answer